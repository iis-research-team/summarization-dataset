Введение

Семантической сегментацией называется процесс классификации объектов изображения и окрашивания каждого объекта в соответствующий классу цвет. Другими словами, для каждого класса объектов определяется свой цвет, например: люди – красный, деревья – зеленый, автомобили – синий.
Далее на изображении выполняется поиск этих объектов, и при их нахождении они окрашиваются в соответствующий цвет. Результатом такой семантической сегментации будет цветовая карта, где достаточно наглядно и просто можно определить отдельные объекты. Это особенно удобно при работе с большими изображениями, содержащими множество мелких объектов, как, например, спутниковые снимки поверхности Земли. Для человека довольно сложно работать с большим количеством таких изображений, это приводит к тому, что постепенно он начинает уставать и совершать ошибки.
Семантическая сегментация находит применение в различных областях, например в беспилотных транспортных средствах для распознавания объектов, в медицине для распознавания изображений на рентгеновских снимках, в системах безопасности и видеонаблюдения и т.д.
Традиционные классические алгоритмы, применяемые для семантической сегментации изображений, основаны на поиске ключевых особенностей объектов, которыми могут быть цвет, форма, текстура, ключевые точки расположения объекта относительно других объектов изображения и т.д.
Относительно этих ключевых характеристик объекты классифицируются и выделяются определенным цветом на изображении [3]. Среди таких алгоритмов можно выделить детекторы и дескрипторы ключевых точек на изображении (SIFT; SURF; FAST; HOG), машину опорных векторов (SVM), Bag of words, метод главных компонент и т.д. Данные алгоритмы активно применялись в конце XX – начале XXI в. К их недостаткам можно отнести низкую устойчивость к различным искажениям входных данных, таким как смена ракурса камеры, шумовые помехи, изменение размера объектов, текстуры, освещения и т.д.
В последние 10 лет им на смену приходят алгоритмы, основанные на искусственных нейронных сетях. Сегодня при решении задач компьютерного зрения нейросетевые алгоритмы показывают лучшие результаты в сравнении со всеми другими алгоритмами.
Применение классических нейронных сетей типа многослойный Персептрон не очень эффективно в работе с изображениями. Связано это с тем, что изображения имеют двумерную структуру, а также важна взаимосвязь пространственно зависимых областей объектов и их частей, которые разрушаются при подаче на вход классических нейронных сетей. Также изображения могут иметь большой размер, что значительно увеличивает размер нейронной сети и снижает ее устойчивость при обучении.
В конце XX в. французским ученым Я. Лекуном был представлен тип нейронных сетей, имеющих двумерную структуру и хорошо подходящих для работы с изображениями. Этот тип нейронных сетей получил название «сверточные нейронные сети» из-за наличия в их структуре операции свертки входных данных. Благодаря некоторым особенностям архитектуры они обеспечивают более высокую устойчивость к различным искажениям на изображениях, смещениям объектов, шумовым помехам, размытию и т.д. Сверточные нейронные сети, как и Персептрон, состоят из нейронов, но имеют двумерную архитектуру, подобную изображениям. Архитектура достаточно сложная и имеет иерархический вид, где каждый слой состоит из различных плоскостей, а каждая плоскость, в свою очередь, представляет собой матрицу нейронов. Каждый нейрон сети получает информацию не со всего изображения, а лишь с отдельной соответствующей ему части. Данный процесс включает в себя операции свертки и подвыборки, благодаря чему входное изображение уменьшается в размере от слоя к слою, в итоге на последних слоях оно вырождается в вектор, где происходит классификация данных. Важная особенность сверточных нейронных сетей заключается в том, что в рамках одной плоскости все нейроны имеют одинаковые весовые коэффициенты, и это значительно снижает количество параметров сети.
Цель работы заключается в разработке нейросетевых алгоритмов, предназначенных для семантической сегментации спутниковых снимков поверхности Земли.
Работу можно разделить на следующие основные этапы:
1. Подготовка достаточного количества изображений поверхности Земли для обучения и тестирования нейронной сети.
2. Разработка архитектуры нейронной сети.
3. Обучение и тестирование нейронной сети.
4. Анализ работы нейронных сетей различной архитектуры с целью выявления более эффективной. 1. Выбор инструментов и среды разработки
В процессе выбора программных средств и среды разработки для нейронных сетей было рассмотрено несколько актуальных на сегодняшний день библиотек машинного обучения: PyTorch – современная библиотека машинного обучения, является аналогом фреймворка Torch для языка Python. Разработка данной библиотеки началась в 2012 г., а в 2017 г. она стала доступной широкой публике. PyTorch содержит достаточно большой функционал и набор алгоритмов машинного обучения. В библиотеке используется динамический граф, что позволяет снизить количество вычислительных процессов и временные затраты на тестирование нейронных сетей.
Keras – библиотека машинного обучения, которая поддерживается компанией Google и предназначена для оперативной работы с глубокими нейронными сетями. Библиотека является компактной, модульной и расширяемой, содержит удобный инструментарий для создания, обучения и тестирования нейронных сетей. Keras представляет собой более высокоуровневую надстройку библиотеки TensorFlow.
Для оценки эффективности применения библиотек использовалась сверточная нейронная сеть VGG16, которая обучалась и тестировалась на базе изображений CIFAR-10. Данная база содержит 60 тыс. изображений десяти различных классов объектов: автомобили, корабли, самолеты, животные и т.д. Результаты тестирования библиотек показали одинаковую скорость работы и точность классификации объектов на уровне 80%. Исходя из этого, в дальнейшей работе было решено использовать библиотеку Keras как более компактную и удобную при создании глубоких нейронных сетей.

2. Архитектура нейронной сети

Глубокие нейронные сети содержат огромное количество параметров, что усложняет определение каких-либо строго формализованных правил при выборе архитектуры сети. Поэтому, как правило, архитектура нейронной сети и прочие параметры выбираются экспериментальным путем.
Так как задачей является семантическая сегментация, то целесообразно использовать нейронные сети класса автоэнкодеры. Данный тип нейронных сетей имеет две фазы в своей работе. Первая фаза заключается в кодировании входных данных в некоторое промежуточное состояние, размерность которого, как правило, меньше исходной размерности данных. Вторая фаза заключается в декодировании данных в новое состояние, размерность которого, как правило, больше промежуточного и может совпадать с исходным.
При выборе архитектуры нейронной сети рассматривались следующие типы автоэнкодеров: U-Net, E-Net, SegNet. Данные сети имеют классическую для автоэнкодеров архитектуру, включающую в себя фазу кодирования и последующую фазу декодирования входных данных. Фаза кодирования содержит несколько сверточных слоев и слоев Max pooling, функцию активации ReLU и применение пакетной нормализации. Фаза декодирования также содержит слои свертки, функцию активации ReLU и применение пакетной нормализации, только вместо Max pooling здесь используется обратная ей функция Unpooling, или Upsampling. Как можно заметить, в данных моделях сетей не используется полносвязный слой нейронов, что значительно сокращает число параметров сети и дает возможность обучения на небольшом количестве обучающих примеров.
Важно, что перечисленные нейронные сети являются очень громоздкими и содержат большое количество слоев. Например, U-Net содержит 23 сверточных слоя, плюс в каждом из них применяются пакетная нормализация и функция активации ReLU, 4 слоя Max pooling, 4 слоя Upsampling, в конце функция активации Softmax. В сумме получается 31 слой.
SegNet содержит 26 сверточных слоев, в каждом из которых применяются пакетная нормализация и функция активации ReLU, 5 слоев Max pooling, 5 слоев Upsampling, в конце функция активации Softmax. В сумме получается 36 слоев.
E-Net содержит 17 сверточных слоев, в каждом из которых применяются пакетная нормализация и функция активации ReLU, 3 слоя Sabsampling, 3 слоя Upsampling, в конце функция активации Softmax. В сумме получается 23 слоя.
В процессе реализации и тестирования перечисленных нейронных сетей они показали сопоставимые результаты в плане точности работы – на уровне 92–95%. Однако в связи с огромным размером они очень долго и не всегда стабильно обучаются. Поэтому было решено разработать нейронную сеть с оригинальной архитектурой с целью уменьшения количества слоев и, как следствие, улучшения качества обучения, но без потери точности работы.
В процессе проведенных исследований была разработана модель нейронной сети, состоящая из 15 слоев (рис. 1). В данной модели первые 8 слоев выполняют кодирование входного изображения в промежуточный вектор. За ними следуют 7 слоев, которые выполняют декодирование этого вектора и перевод его в 3 цветовых канала. Выходное изображение представляет собой результат сегментации данных по различным классам: дома, суша, дороги, растения (в том числе и деревья), вода. Нейронная сеть содержит 15 слоев, что почти в два раза меньше, чем в вышеописанных сетях: 11 сверточных слоев, в каждом из которых применяется функция активации ReLU; 2 слоя Max pooling; 2 слоя Upsampling. Дважды выполняется операция конкатенации данных. Также в данной сети не применяется пакетная нормализация данных. Первые два слоя являются сверточными и содержат каждый по 32 карты признаков. Матрица свертки имеет размер 3 × 3 нейрона. Функция активации ReLu.
Далее следует слой Max pooling, который уменьшает размер карт признаков в 2 раза.
Четвертый и пятый слои являются сверточными и содержат каждый по 64 карты признаков.
Матрица свертки имеет размер 5 × 5 нейронов. Функция активации ReLu.
Далее следует слой Max pooling, который уменьшает размер карт признаков в 2 раза.
Седьмой и восьмой слои являются сверточными и содержат каждый по 128 карт признаков.
Матрица свертки имеет размер 7 × 7 нейронов. Функция активации ReLu.
Девятый слой является слоем Upsamling, который увеличивает размер карт признаков в два раза и является операцией, обратной Max pooling. Далее выполняется конкатенация данных.
Десятый и одиннадцатый слои являются слоями свертки и содержат по 64 карты признаков.
Матрица свертки имеет размер 5 × 5 нейронов. Функция активации ReLu.
Двенадцатый слой является слоем Upsamling и увеличивает размер карт признаков в два раза.
Далее выполняется конкатенация данных.
Тринадцатый и четырнадцатый слои являются сверточными и содержат по 32 карты признаков.
Матрица свертки имеет размер 3 × 3 нейрона. Функция активации ReLu.
Последний слой также является сверточным и содержит 6 карт признаков, соответствующих шести классам объектов на изображениях. Матрица свертки имеет размер 3 × 3 нейрона. Функция активации Softmax.
Во всех слоях свертки применяется функция padding, которая восстанавливает размер изображения.

3. Обучение нейронной сети

В качестве обучающей и тестовой выборок используется набор изображений Humans in the Loop, который разрабатывался для совместного проекта с Космическим центром Мохаммеда Бин Рашида в Дубае (ОАЭ) и находится в открытом доступе. Набор данных состоит из 63 аэрофотоснимков Дубая, полученных со спутников MBRSC. Для каждого изображения в наборе есть соответствующая ему маска, где каждый класс объектов окрашен в определенный цвет. Примеры исходных изображений и соответствующих им сегментированных масок можно увидеть на рис. 2, 3.
Выборка была разделена на 43 изображения для обучения и 20 изображений для тестирования.
Так как изображения в выборке изначально имеют разный размер, то предварительно, перед обучением и тестированием, они были приведены к одному размеру – 500 × 500 пикселей.
Изображения содержат следующие классы объектов:
– дома (темно-синий цвет);
– суша (фиолетовый);
– дороги (голубой);
– растения, деревья (желтый);
– вода (оранжевый);
– нейтральные объекты (серый).
В качестве нейтральных объектов могут выступать объекты, которые случайно оказались в кадре: пролетающий самолет, птицы, автомобили, шумовые помехи т.д.
При выборе алгоритмов обучения рассматривались оптимизаторы, функционирующие на базе алгоритма обратного распространения ошибки. Данный алгоритм впервые был описан в 1974 г. А.И. Галушкиным, а также П.Дж. Вербосом. Особую значимость данный алгоритм приобрел в 1986 г., когда Д. Хинтон, Д. Румельхарт и Р. Уильямс применили его для обучения нейронных сетей. В основе алгоритма лежит метод градиентного спуска, за счет чего достигается минимизация ошибки выходного сигнала нейронной сети. Из недостатков алгоритма можно выделить возможное застревание в локальных минимумах при выборе малого шага или расходимость алгоритма при выборе большого шага обучения. С целью устранения этих недостатков используются некоторые оптимизаторы данного алгоритма. Было проведено исследование работы некоторых оптимизаторов для выбора наиболее подходящего:
– Adam – метод стохастического градиентного спуска, основанный на адаптивной оценке моментов первого и второго порядка.
– Adagrad – оптимизатор со скоростями обучения для конкретных параметров, которые адаптируются в зависимости от того, как часто параметр обновляется во время обучения.
– Adamax – вариант Adam, основанный на норме бесконечности, представляет собой метод оптимизации первого порядка на базе градиента. Благодаря способности регулировать скорость обучения на основе характеристик данных, он подходит для изучения изменяющегося во времени процесса.
Для улучшения обобщающей способности нейронной сети была проведена аугментация изображений, т.е. внесены различные искажения и модификации в исходные изображения. В результате данного подхода расширяется обучающая выборка путем добавления в нее новых изображений, которые сеть ранее не обрабатывала. Аугментация включала в себя следующие преобразования: сжатие и растяжение изображения; отзеркаливание изображения; смещение изображения; размытие.
В табл. 1 представлены результаты обучения и тестирования с использованием различных алгоритмов оптимизаторов, из которых видно, что все три алгоритма показали достаточно высокие результаты сегментации, однако алгоритм Adam показал наилучшие среди них: точность сегментации 99,55%. Было проведено исследование эффективности работы нейронных сетей различной архитектуры. В табл. 2 отражены результаты работы различных архитектур нейронной сети. Исследование работы нейронных сетей проводилось на наборе тестовых изображений с применением операции аугментации. Для определения результатов сегментации использовались метрики среднего и Хаусдорфового расстояния.
Анализ работы нейронных сетей различной архитектуры показал, что все они обеспечивают достаточно высокую точность сегментации, различия заключаются лишь во времени их обучения.
Чем большее количество слоев содержит сеть, тем дольше она обучается. Также стоит отметить, что слишком большое количество слоев снижает точность сегментации. Как правило, последние слои нейронной сети обучаются хорошо, но чем большее количество слоев в структуре, тем более слабый отклик изменения весов доходит до самых первых слоев. Лучший из представленных результатов сегментации составил точность работы 99,55%.

Заключение

Данная работа посвящена решению задачи семантической сегментации спутниковых снимков поверхности Земли. Цель работы – сегментация изображений Humans in the Loop на шесть различных объектов: дома, суша, дороги, растения, вода, нейтральные объекты. Для решения поставленной задачи была реализована модель нейронной сети класса автоэнкодеры с оригинальной компактной архитектурой. Точность работы составила 99,55%. При выборе алгоритма обучения применялось три алгоритма оптимизатора. При разработке архитектуры нейронной сети применялось различное количество слоев и параметров.